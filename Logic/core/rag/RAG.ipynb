{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001ae07ad4654f36a51934fc1b42be32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eef87d0268b4ac7a0960f0304113994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "459bb3a35c574737a695b3e2d3e609a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1eef87d0268b4ac7a0960f0304113994",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9691dc55fc84e819d1dc0bbc19afe87",
      "value": 8
     }
    },
    "5c0022b886284914be87b6228459e325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7126cd7d519441278252013816472b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f28a42abc804a5e97edd39d19fac347",
       "IPY_MODEL_459bb3a35c574737a695b3e2d3e609a9",
       "IPY_MODEL_95d80492b2be4005a7752a84c7a84bef"
      ],
      "layout": "IPY_MODEL_001ae07ad4654f36a51934fc1b42be32"
     }
    },
    "95d80492b2be4005a7752a84c7a84bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef05a78cdd174ee987b53c114310fde3",
      "placeholder": "​",
      "style": "IPY_MODEL_5c0022b886284914be87b6228459e325",
      "value": " 8/8 [01:28&lt;00:00, 10.13s/it]"
     }
    },
    "9f28a42abc804a5e97edd39d19fac347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7bdaba6b09e401c80c3c8a292648682",
      "placeholder": "​",
      "style": "IPY_MODEL_da3b93f3ee5940e89c1bbc7044c10520",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c7bdaba6b09e401c80c3c8a292648682": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9691dc55fc84e819d1dc0bbc19afe87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da3b93f3ee5940e89c1bbc7044c10520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef05a78cdd174ee987b53c114310fde3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# RAG",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Requirements",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%capture\n!pip install transformers accelerate bitsandbytes langchain langchain-community sentence-transformers faiss-gpu pandas gdown",
   "metadata": {
    "id": "D7qkZVjtPtCt",
    "ExecuteTime": {
     "end_time": "2024-06-26T21:17:12.397756Z",
     "start_time": "2024-06-26T21:17:07.526742Z"
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:00.894680Z",
     "iopub.execute_input": "2024-06-28T20:16:00.895425Z",
     "iopub.status.idle": "2024-06-28T20:16:13.457942Z",
     "shell.execute_reply.started": "2024-06-28T20:16:00.895387Z",
     "shell.execute_reply": "2024-06-28T20:16:13.456742Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!gdown --fuzzy https://drive.google.com/file/d/1Lq2zVJlN_B4kUAu4VafQ4jXMIQiAR9vI/view?usp=sharing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KU3LtV3zPtCu",
    "outputId": "b3a2df01-12a9-4afc-d353-deac5300376b",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-26T21:17:14.117601Z"
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:13.459964Z",
     "iopub.execute_input": "2024-06-28T20:16:13.460362Z",
     "iopub.status.idle": "2024-06-28T20:16:17.783258Z",
     "shell.execute_reply.started": "2024-06-28T20:16:13.460330Z",
     "shell.execute_reply": "2024-06-28T20:16:17.782357Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "c## Config",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Config:\n    EMBEDDING_MODEL_NAME=\"thenlper/gte-base\"\n    LLM_MODEL_NAME=\"HuggingFaceH4/zephyr-7b-beta\"\n    K = 5 # top K retrieval",
   "metadata": {
    "id": "MUqmeYExPtCv",
    "jupyter": {
     "is_executing": true
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:17.784796Z",
     "iopub.execute_input": "2024-06-28T20:16:17.785197Z",
     "iopub.status.idle": "2024-06-28T20:16:17.790427Z",
     "shell.execute_reply.started": "2024-06-28T20:16:17.785159Z",
     "shell.execute_reply": "2024-06-28T20:16:17.789567Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## packages",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install -U langchain_huggingface",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:17.791484Z",
     "iopub.execute_input": "2024-06-28T20:16:17.791742Z",
     "iopub.status.idle": "2024-06-28T20:16:30.265781Z",
     "shell.execute_reply.started": "2024-06-28T20:16:17.791720Z",
     "shell.execute_reply": "2024-06-28T20:16:30.264683Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import nltk\nimport pandas as pd\nimport os\nimport re\nfrom nltk.stem import WordNetLemmatizer\nimport subprocess\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import wordnet\nimport pickle\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain.vectorstores.utils import DistanceStrategy\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain_huggingface import HuggingFaceEmbeddings\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom transformers import pipeline\nfrom langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain.chains.combine_documents import create_stuff_documents_chain",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:30.268565Z",
     "iopub.execute_input": "2024-06-28T20:16:30.268901Z",
     "iopub.status.idle": "2024-06-28T20:16:58.304535Z",
     "shell.execute_reply.started": "2024-06-28T20:16:30.268872Z",
     "shell.execute_reply": "2024-06-28T20:16:58.303778Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "nltk.download('wordnet')\nnltk.download('stopwords')\nnltk.download('punkt')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:58.305563Z",
     "iopub.execute_input": "2024-06-28T20:16:58.306007Z",
     "iopub.status.idle": "2024-06-28T20:16:58.672809Z",
     "shell.execute_reply.started": "2024-06-28T20:16:58.305980Z",
     "shell.execute_reply": "2024-06-28T20:16:58.671911Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import nltk\nimport subprocess\n\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n\nfrom nltk.corpus import wordnet",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:58.673965Z",
     "iopub.execute_input": "2024-06-28T20:16:58.674329Z",
     "iopub.status.idle": "2024-06-28T20:16:58.706184Z",
     "shell.execute_reply.started": "2024-06-28T20:16:58.674290Z",
     "shell.execute_reply": "2024-06-28T20:16:58.705261Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_json('IMDB_crawled.json')\nDF = df[:1000]\n#DF = df\n\ndf.head()",
   "metadata": {
    "id": "sjdAj0mnPtCv",
    "jupyter": {
     "is_executing": true
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:16:58.707290Z",
     "iopub.execute_input": "2024-06-28T20:16:58.707561Z",
     "iopub.status.idle": "2024-06-28T20:17:00.905302Z",
     "shell.execute_reply.started": "2024-06-28T20:16:58.707538Z",
     "shell.execute_reply": "2024-06-28T20:17:00.904459Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "os.makedirs('data', exist_ok=True)\n\n# preprocess your data and only store the needed data as the context window for embedding model is limited\n# will be using the preprocess from proj\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\ndef remove_links(text: str):\n    patterns = [r'\\S*http\\S*', r'\\S*www\\S*', r'\\S+\\.ir\\S*', r'\\S+\\.com\\S*', r'\\S+\\.org\\S*', r'\\S*@\\S*']\n    for patt in patterns:\n        text = re.sub(patt, \"\", text)\n    return text\n\ndef remove_punctuations(text: str):\n    return re.sub(r'[^\\w\\s]', '', text)\n\ndef normalize(text: str):\n    return \" \".join([lemmatizer.lemmatize(w.lower()) for w in word_tokenize(text)])\n\ndef remove_stopwords(text: str):\n    return \" \".join([word for word in word_tokenize(text) if word not in set(stopwords.words('english'))])\n\ndef remove_characters(text: str):\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+[a-z]\\s+', ' ', text)\n    text = re.sub(r'^[a-z]\\s+', ' ', text)\n    return text\n\ndef preprocess_text(text: str):\n    text = text.lower()\n    text = remove_stopwords(text)\n    #text = remove_links(text)\n    #text = remove_punctuations(text)\n    text = normalize(text)\n    #text = remove_characters(text)\n    return text\n\nDF = DF[[\"id\", \"title\", \"first_page_summary\", \"genres\"]]\nDF = DF.dropna()\nDF[\"first_page_summary\"] = DF[\"first_page_summary\"].apply(preprocess_text)\n\n\nDF.to_csv('data/imdb.csv', index=False)            \nDF = DF[[\"first_page_summary\", \"genres\"]]\nDF.head()              \n",
   "metadata": {
    "id": "jYJlIaTWPtCw",
    "ExecuteTime": {
     "end_time": "2024-06-26T06:36:15.022204Z",
     "start_time": "2024-06-26T06:36:11.217916Z"
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:00.906597Z",
     "iopub.execute_input": "2024-06-28T20:17:00.906895Z",
     "iopub.status.idle": "2024-06-28T20:17:07.519872Z",
     "shell.execute_reply.started": "2024-06-28T20:17:00.906869Z",
     "shell.execute_reply": "2024-06-28T20:17:07.518845Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Vectorizer",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "load the CSV file and vectorize the rows using HuggingFaceEmbeddings.\nStore the results using FAISS vectorstore.\nSave the vectorestore in a pickle file for future usages.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# load the csv\ndocuments = CSVLoader(\"data/imdb.csv\").load()\n\n# load the embeddings model\n#embeddings_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\nembeddings_model = HuggingFaceEmbeddings(model_name=Config.EMBEDDING_MODEL_NAME)\n\n# save embed the documents using the model in a vectorstore\nvectorstore = FAISS.from_documents(documents, embeddings_model, distance_strategy=DistanceStrategy.COSINE)\n\n\nwith open(\"data/vectorstore.pkl\", \"wb\") as f:\n     pickle.dump(vectorstore, f)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WafXxVaPtCw",
    "outputId": "6645aae7-6325-48f1-a631-e6349362cf7f",
    "ExecuteTime": {
     "end_time": "2024-06-26T06:48:25.868237Z",
     "start_time": "2024-06-26T06:48:25.416377Z"
    },
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:07.521898Z",
     "iopub.execute_input": "2024-06-28T20:17:07.522298Z",
     "iopub.status.idle": "2024-06-28T20:17:16.287708Z",
     "shell.execute_reply.started": "2024-06-28T20:17:07.522257Z",
     "shell.execute_reply": "2024-06-28T20:17:16.286520Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "load the vectorstore as a retriever.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "with open(\"data/vectorstore.pkl\", \"rb\") as f:\n    vectorstore = pickle.load(f)\n\n# load the retriever from the vectorstore\nretriever = vectorstore.as_retriever(k = Config.K)",
   "metadata": {
    "id": "sN1YgCMGPtCw",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:16.289223Z",
     "iopub.execute_input": "2024-06-28T20:17:16.289979Z",
     "iopub.status.idle": "2024-06-28T20:17:16.821921Z",
     "shell.execute_reply.started": "2024-06-28T20:17:16.289941Z",
     "shell.execute_reply": "2024-06-28T20:17:16.820875Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## LLM",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "load the quantized LLM.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# load the quantization config\nbnb_config = BitsAndBytesConfig()\n\nmodel = AutoModelForCausalLM.from_pretrained(Config.LLM_MODEL_NAME, quantization_config=bnb_config, device_map=\"cuda:0\")\ntokenizer = AutoTokenizer.from_pretrained(Config.LLM_MODEL_NAME)\n\n# init the pipeline\nREADER_LLM = pipeline(\"text-generation\", max_new_tokens=2000, model=model, tokenizer=tokenizer)\n\nllm = HuggingFacePipeline(\n    pipeline=READER_LLM,\n)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "7126cd7d519441278252013816472b58",
      "9f28a42abc804a5e97edd39d19fac347",
      "459bb3a35c574737a695b3e2d3e609a9",
      "95d80492b2be4005a7752a84c7a84bef",
      "001ae07ad4654f36a51934fc1b42be32",
      "c7bdaba6b09e401c80c3c8a292648682",
      "da3b93f3ee5940e89c1bbc7044c10520",
      "1eef87d0268b4ac7a0960f0304113994",
      "c9691dc55fc84e819d1dc0bbc19afe87",
      "ef05a78cdd174ee987b53c114310fde3",
      "5c0022b886284914be87b6228459e325"
     ]
    },
    "id": "JM1GYo6HR2MB",
    "outputId": "729df36c-bc0f-4167-e743-d582b35fd388",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:16.823226Z",
     "iopub.execute_input": "2024-06-28T20:17:16.823543Z",
     "iopub.status.idle": "2024-06-28T20:17:34.593669Z",
     "shell.execute_reply.started": "2024-06-28T20:17:16.823512Z",
     "shell.execute_reply": "2024-06-28T20:17:34.592679Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "initialize the prompt template for the query chain. query chain is used to get a query from the chat history. you may change the prompt as you like to get better results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class LoggerStrOutputParser(StrOutputParser):\n    def parse(self, text: str) -> str:\n        # process the LLM output\n        print(f\"QUERY: {text}\")\n        return text\n\nquery_transform_prompt = PromptTemplate(\n    input_variables=[\"messages\"],\n    template=\"\"\"<|system|>You are a helpful assistant.\n{messages}\n<|user|>\ngive me the search query about the above conversation.\n<|assistant|>\"\"\"\n)\n\n# init the query chain\nquery_transforming_retriever_chain = (\n    {\"messages\": RunnablePassthrough()} | query_transform_prompt | llm | StrOutputParser())",
   "metadata": {
    "id": "1eM1zuNUgMPq",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:34.594979Z",
     "iopub.execute_input": "2024-06-28T20:17:34.595367Z",
     "iopub.status.idle": "2024-06-28T20:17:34.602760Z",
     "shell.execute_reply.started": "2024-06-28T20:17:34.595339Z",
     "shell.execute_reply": "2024-06-28T20:17:34.601679Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "initialize the main retrieval chain that gives the resulting documents to LLM and gets the output back.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "prompt = PromptTemplate(\n    input_variables=[\"context\", \"messages\"],\n    template=\"\"\"You are a helpful assistant.\n\nHere are the movies you MUST choose from:\n\n{context}\n-----------------\n{messages}\n-----------------\nUsing above movies and user queries, generate a response containing most relevant movies to the user query.\nyour response doesnt need extra description just list them movies by mentioning title, genres and summary.\nthe queries can be related.\n\"\"\"+ \"|SEP|\")\n\n# init the retriver chain\nretrieval_chain = ({\"context\" : retriever, \"messages\": RunnablePassthrough()} | prompt| llm | StrOutputParser())",
   "metadata": {
    "id": "KwMTLauLS7m0",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:34.606651Z",
     "iopub.execute_input": "2024-06-28T20:17:34.607682Z",
     "iopub.status.idle": "2024-06-28T20:17:34.618563Z",
     "shell.execute_reply.started": "2024-06-28T20:17:34.607651Z",
     "shell.execute_reply": "2024-06-28T20:17:34.617872Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "write the conversation helper class for easier testing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Conversation:\n    def __init__(self):\n        self.messages = []\n\n    def add_assistant_message(self, message):\n        self.messages.append(('assistant', message))\n\n    def add_user_message(self, message):\n        self.messages.append(('user', message))\n\n    def get_messages(self):\n        # concatenate the messages with the roles in the instruction format\n        return \"\\n\".join([f\"{r}: {m}\" for r, m in self.messages])\n\n    def chat(self, message):\n        self.add_user_message(message)\n        messages = self.get_messages()\n        # invoke the chain\n        SQ = query_transforming_retriever_chain.invoke(input=messages).split(\"|SEP|\")[-1]\n        response = retrieval_chain.invoke(SQ).split(\"|SEP|\")[-1]\n        self.add_assistant_message(response)\n        return response",
   "metadata": {
    "id": "zhttNbN0U0WF",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:34.619653Z",
     "iopub.execute_input": "2024-06-28T20:17:34.619927Z",
     "iopub.status.idle": "2024-06-28T20:17:34.631965Z",
     "shell.execute_reply.started": "2024-06-28T20:17:34.619904Z",
     "shell.execute_reply": "2024-06-28T20:17:34.631289Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Test",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "talk with the RAG to see how good it performs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "c = Conversation()\nA = c.chat('give me a cool gangster movie')\nprint(A)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8XV3HvhVTNu",
    "outputId": "b96ea4b1-8d98-4a03-9e67-a41c7a2b3829",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:34.632915Z",
     "iopub.execute_input": "2024-06-28T20:17:34.633184Z",
     "iopub.status.idle": "2024-06-28T20:17:58.202597Z",
     "shell.execute_reply.started": "2024-06-28T20:17:34.633162Z",
     "shell.execute_reply": "2024-06-28T20:17:58.201398Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "A = c.chat('give me a newer one')\nprint(A)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC0Sz0Nbl_Zr",
    "outputId": "092b4108-3ace-4261-ca52-108828ec3e3b",
    "execution": {
     "iopub.status.busy": "2024-06-28T20:17:58.203649Z",
     "iopub.execute_input": "2024-06-28T20:17:58.203915Z",
     "iopub.status.idle": "2024-06-28T20:18:32.288049Z",
     "shell.execute_reply.started": "2024-06-28T20:17:58.203892Z",
     "shell.execute_reply": "2024-06-28T20:18:32.287078Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  }
 ]
}
